{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWyp5/iljp1gGR9uK++wIt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajeevsingh717/Notebooks/blob/main/learn_spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plQPN8YxOTFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8c1f3d9-dfd3-494f-8533-ee695d60f113"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285398 sha256=ae15ac6c38b20e769bc3dac9127d8ef1610c863ffe846b19133b3e778cc6c788\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"MySparkSession\").getOrCreate()\n"
      ],
      "metadata": {
        "id": "sr9wdCEXPlEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample DataFrame creation\n",
        "data = [[\"Alice\", 34], [\"Bob\", 45], [\"Cathy\", 29]]\n",
        "columns = [\"Name\", \"Age\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Display DataFrame content\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJp5vNvhRWsG",
        "outputId": "27b0ac1f-8e7a-483a-b934-188f9ab4072b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| Name|Age|\n",
            "+-----+---+\n",
            "|Alice| 34|\n",
            "|  Bob| 45|\n",
            "|Cathy| 29|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_path = \"/content/citibike.csv\"\n",
        "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
        "\n",
        "# Filter the data\n",
        "filtered_df = df.filter(df[\"min_temperature\"] > 70)\n",
        "\n",
        "# Group by \"age\" and calculate the count\n",
        "year_count = df.groupBy(\"year\").count()\n",
        "\n",
        "# Display the filtered DataFrame and age_count\n",
        "filtered_df.show()\n",
        "age_count.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCooYEvqSdaI",
        "outputId": "cb27c9b6-832b-4fba-ed25-f04f45a25533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+-------------+----------+--------+---------------+---------------+------------------+---+----+-----+-------+-------------------+-------+-------------------+\n",
            "|      date|trips|precipitation|snow_depth|snowfall|max_temperature|min_temperature|average_wind_speed|dow|year|month|holiday|stations_in_service|weekday|weekday_non_holiday|\n",
            "+----------+-----+-------------+----------+--------+---------------+---------------+------------------+---+----+-----+-------+-------------------+-------+-------------------+\n",
            "|2013-07-01|16650|     0.838583|       0.0|     0.0|           77.0|          71.96|           3.13171|  1|2013|    7|  false|                 NA|   true|               true|\n",
            "|2013-07-02|22745|    0.0787402|       0.0|     0.0|          82.04|          71.96|           2.68432|  2|2013|    7|  false|                 NA|   true|               true|\n",
            "|2013-07-03|21864|     0.531496|       0.0|     0.0|          82.94|          73.04|           4.25018|  3|2013|    7|  false|                 NA|   true|               true|\n",
            "|2013-07-04|22326|          0.0|       0.0|     0.0|          87.08|          75.02|           4.25018|  4|2013|    7|   true|                 NA|   true|              false|\n",
            "|2013-07-05|21842|          0.0|       0.0|     0.0|          89.96|          75.92|           4.92126|  5|2013|    7|  false|                 NA|   true|               true|\n",
            "|2013-07-06|20467|          0.0|       0.0|     0.0|          91.94|          78.08|           4.47387|  6|2013|    7|  false|                 NA|  false|              false|\n",
            "|2013-07-07|20477|          0.0|       0.0|     0.0|          91.94|          78.08|           4.25018|  0|2013|    7|  false|                 NA|  false|              false|\n",
            "|2013-07-08|21615|     0.220472|       0.0|     0.0|          89.06|          73.04|           4.69757|  1|2013|    7|  false|                 NA|   true|               true|\n",
            "|2013-07-09|26641|     0.228346|       0.0|     0.0|          87.98|          73.94|           3.13171|  2|2013|    7|  false|                 NA|   true|               true|\n",
            "|2013-07-10|25732|          0.0|       0.0|     0.0|          84.92|          75.02|           4.25018|  3|2013|    7|  false|                 NA|   true|               true|\n",
            "|2013-07-11|24417|          0.0|       0.0|     0.0|          84.02|          75.92|           3.80279|  4|2013|    7|  false|                 NA|   true|               true|\n",
            "|2013-07-14|29287|          0.0|       0.0|     0.0|          89.96|          73.94|           4.02649|  0|2013|    7|  false|                 NA|  false|              false|\n",
            "|2013-07-15|28069|          0.0|       0.0|     0.0|          93.92|          78.08|            3.5791|  1|2013|    7|  false|                 NA|   true|               true|\n",
            "|2013-07-16|29842|          0.0|       0.0|     0.0|          93.92|           77.0|           4.69757|  2|2013|    7|  false|                 NA|   true|               true|\n",
            "|2013-07-17|30550|          0.0|       0.0|     0.0|          96.98|          78.98|            3.3554|  3|2013|    7|  false|                 NA|   true|               true|\n",
            "|2013-07-18|28869|          0.0|       0.0|     0.0|          98.06|          80.96|           3.80279|  4|2013|    7|  false|                 NA|   true|               true|\n",
            "|2013-07-19|26591|          0.0|       0.0|     0.0|          96.08|          82.94|           5.14495|  5|2013|    7|  false|                 NA|   true|               true|\n",
            "|2013-07-20|25278|          0.0|       0.0|     0.0|          93.02|          80.96|           5.81603|  6|2013|    7|  false|                 NA|  false|              false|\n",
            "|2013-07-21|30297|          0.0|       0.0|     0.0|          89.06|          75.92|           4.69757|  0|2013|    7|  false|                 NA|  false|              false|\n",
            "|2013-07-22|25979|    0.0590551|       0.0|     0.0|           86.0|          75.02|           4.92126|  1|2013|    7|  false|                 NA|   true|               true|\n",
            "+----------+-----+-------------+----------+--------+---------------+---------------+------------------+---+----+-----+-------+-------------------+-------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+----+-----+\n",
            "|year|count|\n",
            "+----+-----+\n",
            "|2015|  334|\n",
            "|2013|  184|\n",
            "|2014|  365|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text data\n",
        "text_data = [\n",
        "    \"Hello, how are you?\",\n",
        "    \"I am doing well, thank you!\",\n",
        "    \"How about you?\",\n",
        "    \"I am glad to meet you.\"\n",
        "]\n",
        "\n",
        "# Create a DataFrame from the text data\n",
        "text_df = spark.createDataFrame([(sentence,) for sentence in text_data], [\"text\"])\n",
        "text_df.show()\n",
        "\n",
        "# Split the text into words\n",
        "words_df = text_df.selectExpr(\"split(text, ' ') as words\")\n",
        "words_df.show()\n",
        "\n",
        "# Explode the words into separate rows\n",
        "word_count_df = words_df.selectExpr(\"explode(words) as word\").groupBy(\"word\").count()\n",
        "\n",
        "# Display the word count DataFrame\n",
        "word_count_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QStaW5MVU8R7",
        "outputId": "0c5f7bb4-74be-4665-b0bd-7610e0e4ad05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                text|\n",
            "+--------------------+\n",
            "| Hello, how are you?|\n",
            "|I am doing well, ...|\n",
            "|      How about you?|\n",
            "|I am glad to meet...|\n",
            "+--------------------+\n",
            "\n",
            "+--------------------+\n",
            "|               words|\n",
            "+--------------------+\n",
            "|[Hello,, how, are...|\n",
            "|[I, am, doing, we...|\n",
            "|  [How, about, you?]|\n",
            "|[I, am, glad, to,...|\n",
            "+--------------------+\n",
            "\n",
            "+------+-----+\n",
            "|  word|count|\n",
            "+------+-----+\n",
            "| well,|    1|\n",
            "|  you!|    1|\n",
            "|   how|    1|\n",
            "| doing|    1|\n",
            "| thank|    1|\n",
            "|  you?|    2|\n",
            "|   are|    1|\n",
            "|     I|    2|\n",
            "|Hello,|    1|\n",
            "|    am|    2|\n",
            "|  you.|    1|\n",
            "|  glad|    1|\n",
            "|   How|    1|\n",
            "|  meet|    1|\n",
            "| about|    1|\n",
            "|    to|    1|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}